# Terraform AWS Deployment with GitHub Actions

A comprehensive Infrastructure as Code (IaC) solution for deploying AWS resources using Terraform with GitHub Actions CI/CD pipeline, featuring multi-environment support, remote state management, and automated deployments.

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GitHub Repo   â”‚â”€â”€â”€â”€â–¶â”‚  GitHub Actions  â”‚â”€â”€â”€â”€â–¶â”‚   AWS Account   â”‚
â”‚                 â”‚     â”‚                  â”‚     â”‚                 â”‚
â”‚ â€¢ Terraform     â”‚     â”‚ â€¢ Plan/Apply     â”‚     â”‚ â€¢ S3 Buckets    â”‚
â”‚ â€¢ Workflows     â”‚     â”‚ â€¢ Multi-env      â”‚     â”‚ â€¢ DynamoDB      â”‚
â”‚ â€¢ Modules       â”‚     â”‚ â€¢ State Lock     â”‚     â”‚ â€¢ IAM Roles     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                          â–²
                                â”‚                          â”‚
                                â–¼                          â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
                        â”‚   Remote State   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚                  â”‚
                        â”‚ â€¢ S3 Backend     â”‚
                        â”‚ â€¢ DynamoDB Lock  â”‚
                        â”‚ â€¢ State History  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  ```

## ğŸ“ Project Structure

```
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ terraform.yml           # GitHub Actions CI/CD pipeline
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev.tfvars             # Development environment variables
â”‚   â”œâ”€â”€ stag.tfvars            # Staging environment variables
â”‚   â””â”€â”€ prod.tfvars            # Production environment variables
â”œâ”€â”€ main_module/
â”‚   â”œâ”€â”€ s3.tf                  # S3 bucket configuration
â”‚   â”œâ”€â”€ dynamodb.tf            # DynamoDB table configuration
â”‚   â”œâ”€â”€ provider.tf            # AWS provider setup
â”‚   â”œâ”€â”€ variables.tf           # Input variables
â”‚   â””â”€â”€ outputs.tf             # Output values
â”œâ”€â”€ modules/aws/
â”‚   â”œâ”€â”€ s3/                    # Reusable S3 module
â”‚   â”œâ”€â”€ dynamodb/              # Reusable DynamoDB module
â”‚   â””â”€â”€ sqs/                   # Reusable SQS module
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ manage-state-lock.sh   # Custom state lock management
â”œâ”€â”€ setup/
â”‚   â””â”€â”€ state-bucket.tf        # Initial state bucket setup
â”œâ”€â”€ backend.tf.tmpl            # Backend configuration template
â””â”€â”€ README.md                  # This documentation
```

## ğŸš€ Quick Start

### 1. Initial Setup

```bash
# Clone the repository
git clone <repository-url>
cd sanjay-aws-deployment

# Create initial state bucket (one-time setup)
cd setup
terraform init
terraform apply
cd ..
```

### 2. Configure GitHub Secrets

Add these secrets in your GitHub repository (`Settings > Secrets and variables > Actions`):

| Secret Name | Description | Example |
|-------------|-------------|----------|
| `AWS_ACCESS_KEY_ID` | AWS Access Key | `AKIA...` |
| `AWS_SECRET_ACCESS_KEY` | AWS Secret Key | `wJalr...` |
| `AWS_REGION` | Default AWS Region | `us-east-1` |

### 3. Deploy Infrastructure

1. Go to **Actions** tab in GitHub
2. Select **"Terraform AWS Deployment"**
3. Click **"Run workflow"**
4. Choose:
   - **Environment**: `dev`, `stag`, or `prod`
   - **Action**: `plan`, `apply`, or `destroy`
   - **Region**: Target AWS region
5. Click **"Run workflow"**

## ğŸ”§ Configuration

### Environment Variables

Each environment has its own configuration file:

```hcl
# environments/dev.tfvars
environment = "dev"
aws_region  = "us-west-1"

# environments/prod.tfvars
environment = "prod"
aws_region  = "us-east-1"
```

### Backend Configuration

The system automatically configures remote state:

```hcl
terraform {
  backend "s3" {
    bucket         = "ind-tfstate-bucket"
    key            = "terraform/{environment}/terraform.tfstate"
    region         = "us-east-1"
    dynamodb_table = "ind-tfstate-lock"
  }
}
```

## ğŸ­ Modules

### S3 Module

Creates S3 buckets with environment-specific naming:

```hcl
module "s3_bucket" {
  source        = "../modules/aws/s3"
  bucket_name   = "data-test-first"
  environment   = var.environment
  tags          = local.common_tags
  force_destroy = true
}
```

**Features:**
- Unique bucket naming with random suffix
- Versioning enabled
- Environment-based configuration
- Proper ownership controls

### DynamoDB Module

Creates DynamoDB tables for application data:

```hcl
module "dynamodb_table" {
  source     = "../modules/aws/dynamodb"
  table_name = "user-data"
  environment = var.environment
  tags       = local.common_tags
}
```

## ğŸ”„ CI/CD Pipeline

### Workflow Triggers

- **Push to main**: Automatic plan
- **Pull Request**: Automatic plan
- **Manual Dispatch**: Full control over environment and action

### Workflow Steps

1. **Setup**: Checkout code, configure Terraform and AWS credentials
2. **State Management**: Check/create state bucket and DynamoDB table
3. **Lock Management**: Custom state locking with audit trail
4. **Terraform Operations**: Init, plan, apply, or destroy
5. **Resource Import**: Handle existing resources
6. **Cleanup**: Update lock status and cleanup old entries

### Manual Workflow Options

| Input | Options | Description |
|-------|---------|-------------|
| Environment | `dev`, `stag`, `prod` | Target environment |
| Terraform Action | `init`, `plan`, `apply`, `destroy` | Operation to perform |
| AWS Region | `us-west-1 (dev)`, `us-west-2 (stag)`, `us-east-1 (prod)` | Target region |

## ğŸ”’ Security Features

### State Management
- **Remote State**: Stored in S3 with versioning
- **State Locking**: DynamoDB prevents concurrent modifications
- **Encryption**: Server-side encryption for state files
- **Access Control**: Bucket policies restrict public access

### Custom Lock Management

The `manage-state-lock.sh` script provides:
- Lock creation with metadata
- Lock status checking
- Automatic cleanup of old locks
- Audit trail in DynamoDB

```bash
# Create lock
./scripts/manage-state-lock.sh dev create

# Check lock status
./scripts/manage-state-lock.sh dev check

# Release lock
./scripts/manage-state-lock.sh dev release
```

## ğŸŒ Multi-Environment Support

### Environment Isolation

| Environment | Region | Purpose |
|-------------|--------|---------|
| `dev` | us-west-1 | Development and testing |
| `stag` | us-west-2 | Staging and pre-production |
| `prod` | us-east-1 | Production workloads |

### Resource Naming Convention

```
ind-{environment}-{resource-name}-{random-suffix}
```

Examples:
- `ind-dev-data-test-first-abc123`
- `ind-prod-user-data-xyz789`

## ğŸ“Š Monitoring and Observability

### State Lock Tracking

The system tracks all state operations in DynamoDB:

```json
{
  "LockID": "terraform-dev-1234567890",
  "ProcessID": "github-actions-123-1234567890",
  "Environment": "dev",
  "Status": "ACTIVE",
  "Created": "2024-01-01T12:00:00Z"
}
```

### Workflow Outputs

- S3 bucket listings
- DynamoDB lock status
- Resource import results
- Terraform plan/apply outputs

## ğŸ› ï¸ Troubleshooting

### Common Issues

#### State Lock Issues
```bash
# Check current locks
./scripts/manage-state-lock.sh dev check

# Force release if needed
./scripts/manage-state-lock.sh dev release
```

#### Resource Import Conflicts
The workflow automatically imports existing resources:
- S3 buckets
- DynamoDB tables
- IAM roles

#### Workflow Not Triggering
1. Ensure workflow file exists in target branch
2. Check GitHub Actions permissions
3. Verify secrets are configured

### Debug Commands

```bash
# List S3 state objects
aws s3 ls s3://ind-tfstate-bucket/terraform/

# Check DynamoDB locks
aws dynamodb scan --table-name ind-tfstate-lock

# Verify bucket exists
aws s3api head-bucket --bucket ind-tfstate-bucket
```

## ğŸ“‹ Best Practices

### Development Workflow
1. Create feature branch
2. Make infrastructure changes
3. Test in `dev` environment
4. Create pull request (triggers plan)
5. Review and merge
6. Deploy to `stag` for testing
7. Deploy to `prod` after approval

### Security Guidelines
- Never commit AWS credentials
- Use least privilege IAM policies
- Enable MFA for production deployments
- Regularly rotate access keys
- Monitor CloudTrail logs

### State Management
- Always use remote state
- Enable state file versioning
- Implement state locking
- Regular state file backups
- Monitor state file access

## ğŸ”„ Maintenance

### Regular Tasks
- Update Terraform version in workflow
- Rotate AWS credentials
- Clean up old state lock entries
- Review and update IAM policies
- Monitor resource costs

### Backup Strategy
- State files: Automatic S3 versioning
- DynamoDB: Point-in-time recovery enabled
- Code: Git repository with multiple remotes

## ğŸ“š Additional Resources

- [Terraform Documentation](https://www.terraform.io/docs)
- [GitHub Actions Documentation](https://docs.github.com/en/actions)
- [AWS Provider Documentation](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)
- [Terraform Best Practices](https://www.terraform.io/docs/cloud/guides/recommended-practices/index.html)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test in development environment
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

**Need Help?** Check the troubleshooting section or create an issue in the repository.